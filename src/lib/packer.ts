import { Channel } from '@tauri-apps/api/core'
import { exists, stat, readDir, mkdir } from '@tauri-apps/plugin-fs'
import { join } from '@tauri-apps/api/path'
import { ShowError, ShowWarn } from '@/utils/message'
import {
  pak_pack,
  pak_get_header,
  pak_terminate_pack,
  type PackProgressEvent,
  type PakHeaderInfo,
  type PakEntry,
  type PackedPak
} from '@/api/tauri/pak'
import type { FileItem } from '@/store/work'
import { getParentPath } from '@/utils/path'
import i18n from '@/plugins/i18n'

// å®šä¹‰æ–‡ä»¶ç±»å‹
type PackedFile = {
  path: string
  hash: [number, number]
  size: number
}

// æ–‡ä»¶æ ‘æ¸²æŸ“å‡½æ•°
export function renderFileTree(paks: PackedPak[]): string {
  if (paks.length === 0) {
    return i18n.global.t('pack.noFiles')
  }

  let result = ''

  paks.forEach((pak, pakIndex) => {
    const isLastPak = pakIndex === paks.length - 1
    const pakPrefix = isLastPak ? 'â””â”€â”€ ' : 'â”œâ”€â”€ '
    const pakName = pak.path.split(/[/\\]/).pop() || pak.path

    result += `${pakPrefix}ğŸ“¦ ${pakName} (${pak.files.length} files)\n`

    // æŒ‰è·¯å¾„å¯¹æ–‡ä»¶è¿›è¡Œåˆ†ç»„å’Œæ’åº
    const fileTree = buildFileTree(pak.files)
    const childPrefix = isLastPak ? '    ' : 'â”‚   '
    result += renderFileTreeNode(fileTree, childPrefix)
  })

  return result
}

// æ„å»ºæ–‡ä»¶æ ‘ç»“æ„
function buildFileTree(files: PackedFile[]): FileTreeNode {
  const root: FileTreeNode = { name: '', children: new Map(), files: [] }

  files.forEach((file) => {
    const parts = file.path.split(/[/\\]/).filter((part: string) => part.length > 0)
    let current = root

    // éå†è·¯å¾„çš„æ¯ä¸€éƒ¨åˆ†
    for (let i = 0; i < parts.length - 1; i++) {
      const part = parts[i]
      if (!part) continue

      if (!current.children.has(part)) {
        current.children.set(part, { name: part, children: new Map(), files: [] })
      }

      const next = current.children.get(part)
      if (!next) continue
      current = next
    }

    // æ·»åŠ æ–‡ä»¶åˆ°æœ€ç»ˆç›®å½•
    if (parts.length > 0) {
      current.files.push(file)
    }
  })

  return root
}

// æ¸²æŸ“æ–‡ä»¶æ ‘èŠ‚ç‚¹
function renderFileTreeNode(node: FileTreeNode, prefix: string): string {
  let result = ''

  // è·å–æ‰€æœ‰å­ç›®å½•å’Œæ–‡ä»¶ï¼Œå¹¶æ’åº
  const children = Array.from(node.children.values()).sort((a, b) => a.name.localeCompare(b.name))
  const files = node.files.sort((a, b) => a.path.localeCompare(b.path))

  // æ¸²æŸ“å­ç›®å½•
  children.forEach((child, index) => {
    const isLast = index === children.length - 1 && files.length === 0
    const childPrefix = isLast ? 'â””â”€â”€ ' : 'â”œâ”€â”€ '
    const nextPrefix = prefix + (isLast ? '    ' : 'â”‚   ')

    result += `${prefix}${childPrefix}ğŸ“ ${child.name}\n`
    result += renderFileTreeNode(child, nextPrefix)
  })

  // æ¸²æŸ“æ–‡ä»¶
  files.forEach((file, index) => {
    const isLast = index === files.length - 1
    const filePrefix = isLast ? 'â””â”€â”€ ' : 'â”œâ”€â”€ '
    const fileName = file.path.split(/[/\\]/).pop() || file.path
    const fileSize = formatFileSize(file.size)

    result += `${prefix}${filePrefix}ğŸ“„ ${fileName} (${fileSize})\n`
  })

  return result
}

// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
function formatFileSize(bytes: number): string {
  if (bytes === 0) return '0 B'

  const k = 1024
  const sizes = ['B', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))

  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i]
}

// æ–‡ä»¶æ ‘èŠ‚ç‚¹æ¥å£
interface FileTreeNode {
  name: string
  children: Map<string, FileTreeNode>
  files: PackedFile[]
}

export interface ConflictFile {
  relativePath: string
  size?: number
  modifiedDate?: Date
  sources: Array<{ sourcePath: string }>
  selectedSource: number // -1: ç§»é™¤æ–‡ä»¶, 0+: å¯¹åº”æºæ–‡ä»¶ç´¢å¼•
}

export interface ExportConfig {
  mode: 'individual' | 'single'
  exportDirectory: string
  autoDetectRoot: boolean
  fastMode: boolean
}

export interface ExportResult {
  success: boolean
  files: PackedPak[]
  error: string
  fileTree?: string // æ·»åŠ æ–‡ä»¶æ ‘å­—ç¬¦ä¸²æ˜¾ç¤º
}

export interface PackProgress {
  working: boolean
  currentFile: string
  totalFileCount: number
  finishFileCount: number
}

export interface FolderFile {
  relativePath: string
  fullPath: string
  size: number
  modifiedDate: Date
}

export class Packer {
  private progress: PackProgress = {
    working: false,
    currentFile: '',
    totalFileCount: 0,
    finishFileCount: 0
  }

  private result: ExportResult = {
    success: false,
    files: [],
    error: ''
  }

  private conflictResolutions: { [relativePath: string]: number } = {}

  constructor(
    private onProgressUpdate?: (progress: PackProgress) => void,
    private onResultUpdate?: (result: ExportResult) => void
  ) {}

  getProgress(): PackProgress {
    return { ...this.progress }
  }

  getResult(): ExportResult {
    return { ...this.result }
  }

  resetExport(): void {
    this.progress = {
      working: false,
      currentFile: '',
      totalFileCount: 0,
      finishFileCount: 0
    }
    this.result = {
      success: false,
      files: [],
      error: ''
    }
    this.updateCallbacks()
  }

  private updateCallbacks(): void {
    this.onProgressUpdate?.(this.progress)
    this.onResultUpdate?.(this.result)
  }

  private updateProgress(updates: Partial<PackProgress>): void {
    // åˆ›å»ºæ–°çš„å¯¹è±¡å¼•ç”¨ä»¥ç¡®ä¿å“åº”å¼æ›´æ–°
    this.progress = { ...this.progress, ...updates }
    this.updateCallbacks()
  }

  private updateResult(updates: Partial<ExportResult>): void {
    // åˆ›å»ºæ–°çš„å¯¹è±¡å¼•ç”¨ä»¥ç¡®ä¿å“åº”å¼æ›´æ–°
    this.result = { ...this.result, ...updates }
    this.updateCallbacks()
  }

  async handleExport(inputFiles: FileItem[], exportConfig: ExportConfig): Promise<void> {
    console.debug('handleExport', {
      files: inputFiles,
      mode: exportConfig.mode,
      autoDetectRoot: exportConfig.autoDetectRoot,
      exportDirectory: exportConfig.exportDirectory
    })

    this.resetExport()

    try {
      if (exportConfig.mode === 'individual') {
        await this.handleIndividualExport(inputFiles, exportConfig)
      } else if (exportConfig.mode === 'single') {
        await this.handleMergeExport(inputFiles, exportConfig)
      }
    } catch (e) {
      ShowError(e)
    }
  }

  private async handleIndividualExport(
    inputFiles: FileItem[],
    exportConfig: ExportConfig
  ): Promise<void> {
    // è®¾ç½®åˆå§‹è¿›åº¦çŠ¶æ€
    this.updateProgress({
      working: true,
      totalFileCount: inputFiles.length,
      finishFileCount: 0
    })

    const outputFiles: string[] = []

    function sleep(time: number) {
      return new Promise(function (resolve) {
        setTimeout(resolve, time)
      })
    }

    try {
      for (const file of inputFiles) {
        const outputName = this.generateOutputName(file.path, exportConfig)
        let exportDir: string
        if (!exportConfig.exportDirectory) {
          // empty export directory, use input files' directory
          let parentPath = getParentPath(file.path)
          if (!parentPath) {
            throw new Error(i18n.global.t('pack.failedGetParentPath'))
          }
          exportDir = parentPath
        } else {
          exportDir = exportConfig.exportDirectory
        }

        const uniqueOutputName = await this.generateUniqueFileName(exportDir, outputName)
        const outputPath = await join(exportDir, uniqueOutputName)

        const channel = new Channel<PackProgressEvent>()
        channel.onmessage = (event) => {
          this.handlePackProgress(event)
        }

        const processedSources = await this.processSources([file], exportConfig, {})
        console.debug('processedSources', processedSources)

        await pak_pack(processedSources, outputPath, channel)
        outputFiles.push(outputPath)

        // ç­‰å¾…å®Œæˆä¿¡å·ï¼Œç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆï¼Œå†å¼€å§‹ä¸‹ä¸€ä¸ªæ–‡ä»¶
        while (true) {
          await sleep(50)
          if (this.progress.finishFileCount === this.progress.totalFileCount) {
            break
          }
        }
      }

      this.updateProgress({ working: false })
      this.updateResult({
        success: true,
        files: [], // ä¾èµ–workFinishedäº‹ä»¶è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æ ‘
        error: ''
      })
    } catch (error) {
      this.updateProgress({ working: false })
      this.updateResult({
        success: false,
        files: [],
        error: error instanceof Error ? error.message : String(error)
      })
      ShowError(error)
    }
  }

  async handleMergeExport(
    inputFiles: FileItem[],
    exportConfig: ExportConfig
  ): Promise<ConflictFile[]> {
    try {
      // è®¾ç½®åˆå§‹è¿›åº¦çŠ¶æ€
      this.updateProgress({
        working: true,
        totalFileCount: inputFiles.length,
        finishFileCount: 0
      })

      const conflicts = await this.analyzeConflicts(inputFiles)

      if (conflicts.length > 0) {
        // æœ‰å†²çªæ—¶ï¼Œæš‚åœè¿›åº¦çŠ¶æ€ï¼Œç­‰å¾…ç”¨æˆ·è§£å†³å†²çª
        this.updateProgress({ working: false })
        return conflicts
      } else {
        await this.proceedWithMergeExport(inputFiles, exportConfig)
        return []
      }
    } catch (e) {
      this.updateProgress({ working: false })
      this.updateResult({
        success: false,
        files: [],
        error: e instanceof Error ? e.message : String(e)
      })
      ShowError(e)
      return []
    }
  }

  async proceedWithMergeExport(inputFiles: FileItem[], exportConfig: ExportConfig): Promise<void> {
    if (!exportConfig.exportDirectory) {
      throw new Error(i18n.global.t('pack.exportDirRequired'))
    }

    // é‡æ–°è®¾ç½®è¿›åº¦çŠ¶æ€ï¼ˆå¤„ç†å†²çªåé‡æ–°å¼€å§‹ï¼‰
    this.updateProgress({
      working: true,
      totalFileCount: inputFiles.length,
      finishFileCount: 0
    })

    const outputName = this.generateMergedOutputName(inputFiles, exportConfig)
    const outputPath = await join(exportConfig.exportDirectory, outputName)
    if (!(await exists(outputPath))) {
      await mkdir(exportConfig.exportDirectory, { recursive: true })
    }

    try {
      const processedSources = await this.processSources(
        inputFiles,
        exportConfig,
        this.conflictResolutions
      )

      const channel = new Channel<PackProgressEvent>()
      channel.onmessage = (event) => {
        this.handlePackProgress(event)
      }

      await pak_pack(processedSources, outputPath, channel)

      this.updateProgress({ working: false })
      this.updateResult({
        success: true,
        files: [], // ä¾èµ–workFinishedäº‹ä»¶è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶æ ‘
        error: ''
      })
    } catch (error) {
      this.updateProgress({ working: false })
      this.updateResult({
        success: false,
        files: [],
        error: error instanceof Error ? error.message : String(error)
      })
      ShowError(error)
    }
  }

  private handlePackProgress(event: PackProgressEvent): void {
    switch (event.event) {
      case 'workStart':
        this.updateProgress({
          working: true,
          totalFileCount: event.data.count,
          finishFileCount: 0
        })
        break
      case 'fileDone':
        this.updateProgress({
          currentFile: event.data.path,
          finishFileCount: event.data.finishCount
        })
        break
      case 'workFinished':
        // ä»»åŠ¡å…¨éƒ¨å®Œæˆ
        this.updateProgress({ working: false, finishFileCount: this.progress.totalFileCount })
        const paks = event.data?.tree?.paks ?? []
        this.updateResult({
          success: true,
          files: paks,
          fileTree: renderFileTree(paks),
          error: ''
        })
        break
      case 'error':
        this.updateProgress({ working: false })
        this.updateResult({
          success: false,
          files: [],
          error: event.data.error
        })
        ShowError(event.data.error)
        break
    }
  }

  async analyzeConflicts(files: FileItem[]): Promise<ConflictFile[]> {
    try {
      const fileMap = new Map<
        string,
        Array<{ sourcePath: string; size: number; modifiedDate: Date }>
      >()

      for (const file of files) {
        if (file.isFile && file.path.endsWith('.pak')) {
          const headerInfo = await pak_get_header(file.path)
          for (const pakEntry of headerInfo.entries) {
            // æ„å»ºç›¸å¯¹è·¯å¾„ï¼Œç”±äºPakEntryæ²¡æœ‰relativePathå±æ€§ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨å…¶ä»–æ–¹å¼
            const key = `entry_${pakEntry.hashNameLower}_${pakEntry.hashNameUpper}`
            if (!fileMap.has(key)) {
              fileMap.set(key, [])
            }
            fileMap.get(key)!.push({
              sourcePath: `${file.path}:${key}`,
              size: pakEntry.uncompressedSize,
              modifiedDate: new Date()
            })
          }
        } else {
          const folderFiles = await this.scanFolderFiles(file.path)
          for (const folderFile of folderFiles) {
            const key = folderFile.relativePath
            if (!fileMap.has(key)) {
              fileMap.set(key, [])
            }
            fileMap.get(key)!.push({
              sourcePath: folderFile.fullPath,
              size: folderFile.size,
              modifiedDate: folderFile.modifiedDate
            })
          }
        }
      }

      const conflicts: ConflictFile[] = []
      for (const [relativePath, sources] of fileMap) {
        if (sources.length > 1) {
          conflicts.push({
            relativePath,
            size: sources[0]?.size,
            modifiedDate: sources[0]?.modifiedDate,
            sources: sources.map((s) => ({ sourcePath: s.sourcePath })),
            selectedSource: sources.length - 1
          })
        }
      }

      return conflicts
    } catch (error) {
      console.error('Failed to analyze conflicts:', error)
      return []
    }
  }

  private async scanFolderFiles(folderPath: string): Promise<FolderFile[]> {
    const files: FolderFile[] = []

    const scanRecursive = async (currentPath: string, basePath: string) => {
      try {
        const entries = await readDir(currentPath)

        for (const entry of entries) {
          const fullPath = await join(currentPath, entry.name)

          if (entry.isDirectory) {
            await scanRecursive(fullPath, basePath)
          } else {
            const fileStat = await stat(fullPath)
            const relativePath = fullPath.replace(basePath, '').replace(/\\/g, '/')

            files.push({
              relativePath: relativePath.startsWith('/') ? relativePath : '/' + relativePath,
              fullPath,
              size: fileStat.size,
              modifiedDate: fileStat.mtime ? new Date(fileStat.mtime) : new Date()
            })
          }
        }
      } catch (error) {
        console.error('Failed to scan folder:', error)
      }
    }

    await scanRecursive(folderPath, folderPath)
    return files
  }

  private async processSources(
    files: FileItem[],
    exportConfig: ExportConfig,
    resolutions: { [relativePath: string]: number }
  ): Promise<string[]> {
    const sourcePaths = files.map((f) => f.path)

    if (exportConfig.autoDetectRoot) {
      const processedPaths: string[] = []

      for (const path of sourcePaths) {
        // å‘ä¸‹æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ–‡ä»¶
        const firstFile = await this.findFirstFile(path)
        if (!firstFile) {
          processedPaths.push(path)
          continue
        }

        // check if it is a natives/STM/** path
        const parts = firstFile.split(/[/\\]/)
        const nativesIndex = parts.findIndex((p) => p.toLowerCase() === 'natives')
        const stmIndex = parts.findIndex((p) => p.toLowerCase() === 'stm')

        if (nativesIndex >= 0 && stmIndex === nativesIndex + 1) {
          const separator = firstFile.includes('\\') ? '\\' : '/'
          const rootPath = parts.slice(0, nativesIndex + 1).join(separator) // keep xxx/yyy/natives
          processedPaths.push(rootPath)
        } else {
          processedPaths.push(path)
        }
      }

      return [...new Set(processedPaths)]
    }

    return sourcePaths
  }

  private async findFirstFile(rootPath: string): Promise<string> {
    const entries = await readDir(rootPath)
    for (const entry of entries) {
      if (entry.isFile) {
        return await join(rootPath, entry.name)
      } else {
        const firstFile = await this.findFirstFile(await join(rootPath, entry.name))
        if (firstFile) {
          return firstFile
        }
      }
    }
    return ''
  }

  private async generateUniqueFileName(directory: string, baseName: string): Promise<string> {
    let fileName = baseName
    let counter = 1

    while (await exists(await join(directory, fileName))) {
      const nameWithoutExt = baseName.replace(/\.pak$/, '')
      fileName = `${nameWithoutExt}-${counter}.pak`
      counter++
    }

    return fileName
  }

  private generateOutputName(inputPath: string, exportConfig: ExportConfig): string {
    const basename = inputPath.split(/[/\\]/).pop() || 'output'

    if (exportConfig.autoDetectRoot) {
      const parts = inputPath.split(/[/\\]/)
      const nativesIndex = parts.findIndex((p) => p === 'natives')
      if (nativesIndex > 0) {
        return `${parts[nativesIndex - 1]}.pak`
      }
    }

    return basename.endsWith('.pak') ? basename : `${basename}.pak`
  }

  private generateMergedOutputName(inputFiles: FileItem[], exportConfig: ExportConfig): string {
    const firstFile = inputFiles.at(0)
    if (exportConfig.autoDetectRoot && firstFile) {
      const firstPath = firstFile.path
      const parts = firstPath.split(/[/\\]/)
      const nativesIndex = parts.findIndex((p) => p === 'natives')
      if (nativesIndex > 0) {
        return `${parts[nativesIndex - 1]}.pak`
      }
    }

    const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19)
    return `merged-${timestamp}.pak`
  }

  async terminateExport(): Promise<void> {
    try {
      await pak_terminate_pack()
      this.resetExport()
    } catch (error) {
      ShowError(i18n.global.t('pack.failedCancelExport', { error }))
    }
  }

  setConflictResolutions(resolutions: { [relativePath: string]: number }): void {
    this.conflictResolutions = resolutions
  }
}
